## TR:
# Pratik MLOps Proje Koleksiyonu

Bu repository, MLOps (Machine Learning Operations) prensiplerini Ã¼Ã§ farklÄ± yapay zeka alanÄ±nda uygulamalÄ± olarak gÃ¶steren bir proje koleksiyonu iÃ§ermektedir. Her bir proje, modelin eÄŸitilmesinden baÅŸlayarak FastAPI ile bir API olarak sunulmasÄ±na, Streamlit ile bir kullanÄ±cÄ± arayÃ¼zÃ¼ oluÅŸturulmasÄ±na ve test edilmesine kadar olan tÃ¼m yaÅŸam dÃ¶ngÃ¼sÃ¼nÃ¼ kapsar.

## ğŸš€ Projeler ve KullanÄ±lan Teknolojiler

Bu koleksiyon, yapay zekanÄ±n Ã¼Ã§ farklÄ± dalÄ±nÄ± ele alan projelerden oluÅŸur:

| Proje AdÄ± | Alan | Ana KÃ¼tÃ¼phaneler | Model DosyasÄ± |
| :--- | :--- | :--- | :--- |
| **1. Meme Kanseri Tahmini** | Klasik Makine Ã–ÄŸrenmesi (ML) | `Scikit-learn` | `.pkl` |
| **2. El YazÄ±sÄ± Rakam TanÄ±ma** | Derin Ã–ÄŸrenme (DL) | `TensorFlow/Keras` | `.h5` |
| **3. LLM Destekli Chatbot** | BÃ¼yÃ¼k Dil Modelleri (LLM) | `LangChain`, `Ollama` | (Yerel Model) |

**Ortak Teknoloji YÄ±ÄŸÄ±nÄ±:**
- **Backend (API Sunucusu):** `FastAPI`
- **Frontend (KullanÄ±cÄ± ArayÃ¼zÃ¼):** `Streamlit`
- **Model SerileÅŸtirme:** `Joblib`, `H5`

## ğŸ› ï¸ Kurulum ve BaÅŸlangÄ±Ã§

Projeleri Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki genel adÄ±mlarÄ± izleyin. Her projenin kendine Ã¶zgÃ¼ Ã§alÄ±ÅŸtÄ±rma komutlarÄ± ilgili baÅŸlÄ±k altÄ±nda verilmiÅŸtir.

1.  **Repository'yi KlonlayÄ±n:**
    ```bash
    git clone https://github.com/AliDmrcIo/MLOps_Project.git
    cd MLOps_Project
    ```

2.  **Sanal OrtamÄ± Aktif Edin:**
    Proje, gerekli kÃ¼tÃ¼phaneleri iÃ§eren bir `venv` sanal ortamÄ± ile birlikte gelir.
    ```bash
    # Windows iÃ§in
    .\venv\Scripts\activate
    ```

3.  **Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin:**
    `requirements.txt` dosyasÄ± tÃ¼m projeler iÃ§in gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± iÃ§erir.
    ```bash
    pip install -r requirements.txt
    ```

4.  **(Chatbot Projesi iÃ§in) Ollama Kurulumu:**
    `3_chatbot_with_LLM` projesini Ã§alÄ±ÅŸtÄ±rmak iÃ§in sisteminizde [Ollama](https://ollama.com/)'nÄ±n kurulu olmasÄ± ve `llama3.2:3b` modelinin indirilmiÅŸ olmasÄ± gerekmektedir.
    ```bash
    ollama pull llama3.2:3b
    ```

---

## ğŸ“‚ Proje DetaylarÄ± ve Dosya AÃ§Ä±klamalarÄ±

### 1. Meme Kanseri Tahmini (Klasik Makine Ã–ÄŸrenmesi)

Bu proje, Scikit-learn kullanÄ±larak eÄŸitilmiÅŸ bir `RandomForestClassifier` modelinin, hastaya ait Ã¶zelliklere gÃ¶re meme kanserinin iyi huylu mu yoksa kÃ¶tÃ¼ huylu mu olduÄŸunu tahmin etmesini saÄŸlar.

**Dosya YapÄ±sÄ± ve GÃ¶revleri:**
-   `model_train.py`: Modeli `breast_cancer` veri seti ile eÄŸitir ve `breast_cancer_model.pkl` olarak kaydeder.
-   `main.py`: `FastAPI` kullanarak bir web sunucusu oluÅŸturur. Kaydedilen `.pkl` modelini yÃ¼kler ve gelen veri iÃ§in tahmin yapan bir `/predict` endpoint'i sunar.
-   `ui.py`: `Streamlit` ile bir web arayÃ¼zÃ¼ oluÅŸturur. KullanÄ±cÄ±nÄ±n 30 farklÄ± tÄ±bbi Ã¶zelliÄŸi girmesine olanak tanÄ±r ve "Tahmin Et" butonuna basÄ±ldÄ±ÄŸÄ±nda FastAPI'deki `/predict` endpoint'ine istek atarak sonucu gÃ¶sterir.
-   `client_test.py`: FastAPI sunucusunun doÄŸru Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± test etmek iÃ§in `/predict` endpoint'ine programatik olarak Ã¶rnek bir istek gÃ¶nderir.

**NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?**
1.  Terminalde `mlops` klasÃ¶rÃ¼ndeyken sanal ortamÄ± aktif edin.
2.  **Backend'i (API Sunucusu) baÅŸlatÄ±n:**
    ```bash
    uvicorn 1_breast_cancer_project_with_ML.main:app --reload
    ```
3.  Yeni bir terminal aÃ§Ä±n, sanal ortamÄ± tekrar aktif edin ve **Frontend'i (ArayÃ¼z) baÅŸlatÄ±n:**
    ```bash
    streamlit run 1_breast_cancer_project_with_ML/ui.py
    ```

### 2. El YazÄ±sÄ± Rakam TanÄ±ma (Derin Ã–ÄŸrenme)

Bu proje, MNIST veri seti Ã¼zerinde TensorFlow/Keras ile eÄŸitilmiÅŸ bir EvriÅŸimli Sinir AÄŸÄ± (CNN) kullanarak, kullanÄ±cÄ±nÄ±n yÃ¼klediÄŸi bir resimdeki el yazÄ±sÄ± rakamÄ± tanÄ±r.

**Dosya YapÄ±sÄ± ve GÃ¶revleri:**
-   `model_train.py`: MNIST veri seti ile bir CNN modeli oluÅŸturur, eÄŸitir ve `mnist_model.h5` olarak kaydeder.
-   `main.py`: `FastAPI` sunucusu oluÅŸturur. `.h5` modelini yÃ¼kler ve 28x28 piksel boyutundaki gÃ¶rÃ¼ntÃ¼ verisini iÅŸleyerek tahmin yapan bir `/predict` endpoint'i sunar.
-   `ui.py`: `Streamlit` ile bir web arayÃ¼zÃ¼ oluÅŸturur. KullanÄ±cÄ±nÄ±n bir rakam resmi yÃ¼klemesine izin verir. YÃ¼klenen resim, modelin beklediÄŸi formata (gri tonlama, 28x28 boyut, normalizasyon) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve FastAPI'ye gÃ¶nderilir.
-   `client_test.py`: `images/` klasÃ¶rÃ¼ndeki bir test gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ iÅŸleyerek API'yi test eder.
-   `images/`: Test iÃ§in kullanÄ±lacak Ã¶rnek resimleri iÃ§erir.

**NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?**
1.  Terminalde `mlops` klasÃ¶rÃ¼ndeyken sanal ortamÄ± aktif edin.
2.  **Backend'i (API Sunucusu) baÅŸlatÄ±n:**
    ```bash
    uvicorn 2_handwritten_digits_project_with_DL.main:app --reload
    ```
3.  Yeni bir terminal aÃ§Ä±n, sanal ortamÄ± tekrar aktif edin ve **Frontend'i (ArayÃ¼z) baÅŸlatÄ±n:**
    ```bash
    streamlit run 2_handwritten_digits_project_with_DL/ui.py
    ```

### 3. LLM Destekli Chatbot

Bu proje, yerel olarak Ã§alÄ±ÅŸan bir BÃ¼yÃ¼k Dil Modeli (LLaMA 3.2) ve `LangChain` kÃ¼tÃ¼phanesi kullanarak, hafÄ±zasÄ± olan (konuÅŸma geÃ§miÅŸini hatÄ±rlayan) bir chatbot oluÅŸturur.

**Dosya YapÄ±sÄ± ve GÃ¶revleri:**
-   `main.py`: `FastAPI` sunucusu oluÅŸturur. `LangChain` ve `Ollama` kullanarak bir sohbet zinciri (`conversational chain`) kurar. Bu zincir, oturum bazlÄ± hafÄ±za yÃ¶netimi yapar. KullanÄ±cÄ±dan gelen mesajlarÄ± iÅŸleyen bir `/chat` endpoint'i sunar.
-   `ui.py`: `Streamlit` ile klasik bir sohbet arayÃ¼zÃ¼ oluÅŸturur. KullanÄ±cÄ±nÄ±n girdiÄŸi her mesajÄ± FastAPI'deki `/chat` endpoint'ine gÃ¶nderir, gelen cevabÄ± alÄ±r ve sohbet geÃ§miÅŸini ekranda gÃ¶sterir.
-   *(Not: Bu projede `model_train.py` yoktur Ã§Ã¼nkÃ¼ Ã¶nceden eÄŸitilmiÅŸ bir LLM kullanÄ±lmaktadÄ±r. `client_test.py` ise arayÃ¼z Ã¼zerinden kolayca test edilebildiÄŸi iÃ§in bu projeye dahil edilmemiÅŸtir.)*

**NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?**
1.  Terminalde `mlops` klasÃ¶rÃ¼ndeyken sanal ortamÄ± aktif edin.
2.  **Backend'i (API Sunucusu) baÅŸlatÄ±n:**
    ```bash
    uvicorn 3_chatbot_with_LLM.main:app --reload
    ```
3.  Yeni bir terminal aÃ§Ä±n, sanal ortamÄ± tekrar aktif edin ve **Frontend'i (ArayÃ¼z) baÅŸlatÄ±n:**
    ```bash
    streamlit run 3_chatbot_with_LLM/ui.py
    ```

    ## ENG:
    # Practical MLOps Project Collection

This repository contains a collection of projects that demonstrate MLOps (Machine Learning Operations) principles in practice across three different domains of artificial intelligence. Each project covers the entire lifecycle, from model training to deployment as an API with FastAPI, creating a user interface with Streamlit, and testing.

## ğŸš€ Projects and Technologies Used

This collection consists of projects covering three different branches of AI:

| Project Name | Domain | Core Libraries | Model File |
| :--- | :--- | :--- | :--- |
| **1. Breast Cancer Prediction** | Classic Machine Learning (ML) | `Scikit-learn` | `.pkl` |
| **2. Handwritten Digit Recognition**| Deep Learning (DL) | `TensorFlow/Keras` | `.h5` |
| **3. LLM-Powered Chatbot** | Large Language Models (LLM) | `LangChain`, `Ollama` | (Local Model) |

**Common Technology Stack:**
- **Backend (API Server):** `FastAPI`
- **Frontend (User Interface):** `Streamlit`
- **Model Serialization:** `Joblib`, `H5`

## ğŸ› ï¸ Setup and Getting Started

Follow these general steps to run the projects. Specific commands for each project are provided under their respective headings.

1.  **Clone the Repository:**
    ```bash
    git clone https://github.com/AliDmrcIo/MLOps_Project.git
    cd MLOps_Project
    ```

2.  **Activate the Virtual Environment:**
    The project comes with a `venv` virtual environment that includes the necessary libraries.
    ```bash
    # For Windows
    .\venv\Scripts\activate
    ```

3.  **Install Dependencies:**
    The `requirements.txt` file contains all the necessary dependencies for all projects.
    ```bash
    pip install -r requirements.txt
    ```

4.  **(For the Chatbot Project) Install Ollama:**
    To run the `3_chatbot_with_LLM` project, you need to have [Ollama](https://ollama.com/) installed on your system and the `llama3.2:3b` model downloaded.
    ```bash
    ollama pull llama3.2:3b
    ```

---

## ğŸ“‚ Project Details and File Descriptions

### 1. Breast Cancer Prediction (Classic Machine Learning)

This project uses a `RandomForestClassifier` model trained with Scikit-learn to predict whether a breast cancer tumor is benign or malignant based on patient features.

**File Structure and Roles:**
-   `model_train.py`: Trains the model with the `breast_cancer` dataset and saves it as `breast_cancer_model.pkl`.
-   `main.py`: Creates a web server using `FastAPI`. It loads the saved `.pkl` model and serves a `/predict` endpoint that makes predictions on incoming data.
-   `ui.py`: Creates a web interface with `Streamlit`. It allows the user to input 30 different medical features and, upon clicking the "Predict" button, sends a request to the FastAPI `/predict` endpoint to display the result.
-   `client_test.py`: Sends a programmatic sample request to the `/predict` endpoint to test if the FastAPI server is working correctly.

**How to Run:**
1.  In your terminal, activate the virtual environment while in the `mlops` directory.
2.  **Start the Backend (API Server):**
    ```bash
    uvicorn 1_breast_cancer_project_with_ML.main:app --reload
    ```
3.  Open a new terminal, activate the virtual environment again, and **start the Frontend (UI):**
    ```bash
    streamlit run 1_breast_cancer_project_with_ML/ui.py
    ```

### 2. Handwritten Digit Recognition (Deep Learning)

This project uses a Convolutional Neural Network (CNN) trained on the MNIST dataset with TensorFlow/Keras to recognize a handwritten digit from an image uploaded by the user.

**File Structure and Roles:**
-   `model_train.py`: Creates, trains, and saves a CNN model with the MNIST dataset as `mnist_model.h5`.
-   `main.py`: Creates a `FastAPI` server. It loads the `.h5` model and serves a `/predict` endpoint that processes 28x28 pixel image data to make a prediction.
-   `ui.py`: Creates a web interface with `Streamlit`. It allows the user to upload a digit image. The uploaded image is preprocessed into the format expected by the model (grayscale, 28x28, normalization) and sent to the FastAPI server.
-   `client_test.py`: Tests the API by processing a test image from the `images/` folder.
-   `images/`: Contains sample images for testing.

**How to Run:**
1.  In your terminal, activate the virtual environment while in the `mlops` directory.
2.  **Start the Backend (API Server):**
    ```bash
    uvicorn 2_handwritten_digits_project_with_DL.main:app --reload
    ```
3.  Open a new terminal, activate the virtual environment again, and **start the Frontend (UI):**
    ```bash
    streamlit run 2_handwritten_digits_project_with_DL/ui.py
    ```

### 3. LLM-Powered Chatbot

This project creates a chatbot with memory (it remembers conversation history) using a locally running Large Language Model (LLaMA 3.2) and the `LangChain` library.

**File Structure and Roles:**
-   `main.py`: Creates a `FastAPI` server. It sets up a conversational chain using `LangChain` and `Ollama`. This chain manages session-based memory. It serves a `/chat` endpoint that processes incoming user messages.
-   `ui.py`: Creates a classic chat interface with `Streamlit`. It sends each user message to the FastAPI `/chat` endpoint, receives the response, and displays the entire conversation history on the screen.
-   *(Note: This project does not have a `model_train.py` because it uses a pre-trained LLM. A `client_test.py` is also omitted as it can be easily tested via the user interface.)*

**How to Run:**
1.  In your terminal, activate the virtual environment while in the `mlops` directory.
2.  **Start the Backend (API Server):**
    ```bash
    uvicorn 3_chatbot_with_LLM.main:app --reload
    ```
3.  Open a new terminal, activate the virtual environment again, and **start the Frontend (UI):**
    ```bash
    streamlit run 3_chatbot_with_LLM/ui.py
    ```
